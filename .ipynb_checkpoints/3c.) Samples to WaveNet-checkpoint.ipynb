{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This note book uses the WaveNet autoencoder to encode audio samples into the bottleneck features. \n",
    "\n",
    "Engel, Jesse, et al. \"Neural Audio Synthesis of Musical Notes with WaveNet Autoencoders.\" arXiv preprint arXiv:1704.01279 (2017).\n",
    "https://arxiv.org/abs/1704.01279"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/lamtharnhantrakul/anaconda/envs/klustr/lib/python2.7/site-packages/magenta/models/nsynth/wavenet/masked.py:116: __init__ (from tensorflow.python.ops.init_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.initializers.variance_scaling instead with distribution=uniform to get equivalent behavior.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import umap\n",
    "import json\n",
    "import librosa\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet import fastgen\n",
    "from os.path import join\n",
    "from tqdm import tqdm\n",
    "np.random.seed(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_root = 'drumData'\n",
    "n_fft = 1024\n",
    "hop_length = n_fft/4\n",
    "use_logamp = False # boost the brightness of quiet sounds\n",
    "reduce_rows = 10 # how many frequency bands to average into one\n",
    "reduce_cols = 1 # how many time steps to average into one\n",
    "crop_rows = 32 # limit how many frequency bands to use\n",
    "crop_cols = 32 # limit how many time steps to use\n",
    "limit = None # set this to 100 to only process 100 samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load audio matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.17 ms, sys: 334 ms, total: 336 ms\n",
      "Wall time: 496 ms\n",
      "CPU times: user 549 µs, sys: 25.7 ms, total: 26.3 ms\n",
      "Wall time: 47.5 ms\n",
      "CPU times: user 1.78 ms, sys: 166 ms, total: 168 ms\n",
      "Wall time: 448 ms\n",
      "CPU times: user 1.46 ms, sys: 87.5 ms, total: 89 ms\n",
      "Wall time: 128 ms\n",
      "CPU times: user 1.01 ms, sys: 12.8 ms, total: 13.8 ms\n",
      "Wall time: 35.9 ms\n",
      "CPU times: user 1.73 ms, sys: 16.9 ms, total: 18.7 ms\n",
      "Wall time: 34.3 ms\n",
      "CPU times: user 926 µs, sys: 49.7 ms, total: 50.7 ms\n",
      "Wall time: 79.8 ms\n",
      "(5158, 12000)\n",
      "(422, 12000)\n",
      "(2546, 12000)\n",
      "(1324, 12000)\n",
      "(159, 12000)\n",
      "(228, 12000)\n",
      "(723, 12000)\n"
     ]
    }
   ],
   "source": [
    "drumNames = [\"kick\", \"tom\", \"snare\", \"clap\", \"hi.hat\", \"ride\", \"crash\"]\n",
    "drumFingerPrints = {}\n",
    "drumSamples = {}\n",
    "for d in drumNames:\n",
    "    %time drumSamples[d] = np.load(join(data_root, d+'_samples.npy'))\n",
    "for d in drumNames:\n",
    "    print (drumSamples[d].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define test function for encoding based on wavenet model\n",
    "We assume you will not be running the WaveNet model from this notebook. This is because the encoding process takes over 12 hours for our sample set.\n",
    "\n",
    "The WaveNet model can be downloaded from\n",
    "http://download.magenta.tensorflow.org/models/nsynth/wavenet-ckpt.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def wavenet_encode(wave_files):\n",
    "  \n",
    "    encoding = fastgen.encode(wave_files, './wavenet-ckpt/model.ckpt-200000', 12000)\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12000,)\n",
      "(5158, 12000)\n"
     ]
    }
   ],
   "source": [
    "crashes = drumSamples[\"crash\"]\n",
    "kicks = drumSamples[\"kick\"]\n",
    "\n",
    "sample_kick = kicks[0]\n",
    "sample_crash = crashes[0]\n",
    "print(sample_kick.shape)\n",
    "print(kicks.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n"
     ]
    }
   ],
   "source": [
    "# Encdoe one sample\n",
    "wavenet_kick = wavenet_encode(sample_kick)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 23, 16)\n",
      "15.8841\n",
      "-8.46548\n"
     ]
    }
   ],
   "source": [
    "# Check statistics of the embedding space\n",
    "print(wavenet_kick.shape)\n",
    "print(np.max(wavenet_kick))\n",
    "print(np.min(wavenet_kick))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode files using WaveNet\n",
    "The following code block executes the encoding process in parallel. ie, the full (159,12000) matrix is pushed into the model and an output of dimension of (159,23,16) is produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('hi.hat', (159, 23, 16))\n",
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('ride', (228, 23, 16))\n",
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n",
      "('crash', (723, 23, 16))\n"
     ]
    }
   ],
   "source": [
    "# Divide the dataset into two groups: files that will take a really long time\n",
    "# to encode, and samples that will take a little shorted amount of time\n",
    "small_drumset = [\"tom\",\"hi.hat\", \"ride\", \"crash\"]\n",
    "large_drumset = [\"kick\", \"snare\", \"clap\"]\n",
    "\n",
    "for drum_name in small_drumset: \n",
    "    wavenet_features = wavenet_encode(drumSamples[drum_name])\n",
    "    print (drum_name, wavenet_features.shape)  \n",
    "    file_path = './drumEmbeddings/' + drum_name + '_wavenet.npy'\n",
    "    np.save(file_path, wavenet_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For samples with large numbers (>4000) it is impossible to load all samples in memory and push through the model. Thus, we looked at the magenta source-code and re-wrote the `encode()` function to process an audio file in smaller batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from magenta.models.nsynth import utils\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import Config\n",
    "from magenta.models.nsynth.wavenet.h512_bo16 import FastGenerationConfig\n",
    "\n",
    "def custom_encode(wav_data, checkpoint_path, drum_name, sample_length=64000):\n",
    "    batch_size = 1\n",
    "    samples_wavenet = []\n",
    "    num_samples = wav_data.shape[0]\n",
    "    # Load up the model for encoding and find the encoding of \"wav_data\"\n",
    "    session_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    with tf.Graph().as_default(), tf.Session(config=session_config) as sess:\n",
    "        hop_length = Config().ae_hop_length\n",
    "        net = testload_nsynth(batch_size=batch_size, sample_length=11776)  # hardcore to 11776 for samples of length 12000\n",
    "        saver = tf.train.Saver()\n",
    "        saver.restore(sess, checkpoint_path)\n",
    "        \n",
    "        for i in tqdm(range(num_samples)):\n",
    "            sample = wav_data[i]\n",
    "            sample = np.expand_dims(sample,0)\n",
    "            sample, sample_length = utils.trim_for_encoding(sample, sample_length,hop_length)\n",
    "            encodings = sess.run(net[\"encoding\"], feed_dict={net[\"X\"]: sample})\n",
    "            encodings = encodings.reshape(-1,16)\n",
    "            samples_wavenet.append(encodings)\n",
    "        samples_wavenet = np.asarray(samples_wavenet)\n",
    "        \n",
    "        file_path = './drumEmbeddings/' + drum_name + '_wavenet.npy'\n",
    "        np.save(file_path, samples_wavenet)\n",
    "        print (drum_name, samples_wavenet.shape) \n",
    "        \n",
    "def testload_nsynth(batch_size=1, sample_length=64000):\n",
    "    \"\"\"Load the NSynth autoencoder network.\n",
    "    Args:\n",
    "    batch_size: Batch size number of observations to process. [1]\n",
    "    sample_length: Number of samples in the input audio. [64000]\n",
    "    Returns:\n",
    "    graph: The network as a dict with input placeholder in {\"X\"}\n",
    "    \"\"\"\n",
    "    config = Config()\n",
    "    with tf.device(\"/gpu:0\"):\n",
    "        x = tf.placeholder(tf.float32, shape=[batch_size, sample_length])\n",
    "        graph = config.build({\"wav\": x}, is_training=False)\n",
    "        graph.update({\"X\": x})\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./wavenet-ckpt/model.ckpt-200000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:14<00:00,  2.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('clap', (5, 23, 16))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "drum_name = \"clap\"\n",
    "custom_encode(drum_name, './wavenet-ckpt/model.ckpt-200000',drum_name, 12000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
